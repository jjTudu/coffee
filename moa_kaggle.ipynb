{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599897361152",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: scikit-multilearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.0)\nWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            cp_time           g-0  ...          c-98          c-99\ncount  23814.000000  23814.000000  ...  23814.000000  23814.000000\nmean      48.020156      0.248366  ...     -0.470252     -0.301505\nstd       19.402807      1.393399  ...      1.834828      1.407918\nmin       24.000000     -5.513000  ...    -10.000000    -10.000000\n25%       24.000000     -0.473075  ...     -0.592600     -0.562900\n50%       48.000000     -0.008850  ...      0.014000     -0.019500\n75%       72.000000      0.525700  ...      0.461275      0.438650\nmax       72.000000     10.000000  ...      3.111000      3.805000\n\n[8 rows x 873 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp_time</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>g-6</th>\n      <th>g-7</th>\n      <th>g-8</th>\n      <th>g-9</th>\n      <th>g-10</th>\n      <th>g-11</th>\n      <th>g-12</th>\n      <th>g-13</th>\n      <th>g-14</th>\n      <th>g-15</th>\n      <th>g-16</th>\n      <th>g-17</th>\n      <th>g-18</th>\n      <th>g-19</th>\n      <th>g-20</th>\n      <th>g-21</th>\n      <th>g-22</th>\n      <th>g-23</th>\n      <th>g-24</th>\n      <th>g-25</th>\n      <th>g-26</th>\n      <th>g-27</th>\n      <th>g-28</th>\n      <th>g-29</th>\n      <th>g-30</th>\n      <th>g-31</th>\n      <th>g-32</th>\n      <th>g-33</th>\n      <th>g-34</th>\n      <th>g-35</th>\n      <th>g-36</th>\n      <th>g-37</th>\n      <th>g-38</th>\n      <th>...</th>\n      <th>c-60</th>\n      <th>c-61</th>\n      <th>c-62</th>\n      <th>c-63</th>\n      <th>c-64</th>\n      <th>c-65</th>\n      <th>c-66</th>\n      <th>c-67</th>\n      <th>c-68</th>\n      <th>c-69</th>\n      <th>c-70</th>\n      <th>c-71</th>\n      <th>c-72</th>\n      <th>c-73</th>\n      <th>c-74</th>\n      <th>c-75</th>\n      <th>c-76</th>\n      <th>c-77</th>\n      <th>c-78</th>\n      <th>c-79</th>\n      <th>c-80</th>\n      <th>c-81</th>\n      <th>c-82</th>\n      <th>c-83</th>\n      <th>c-84</th>\n      <th>c-85</th>\n      <th>c-86</th>\n      <th>c-87</th>\n      <th>c-88</th>\n      <th>c-89</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>...</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>48.020156</td>\n      <td>0.248366</td>\n      <td>-0.095684</td>\n      <td>0.152253</td>\n      <td>0.081971</td>\n      <td>0.057347</td>\n      <td>-0.138836</td>\n      <td>0.035961</td>\n      <td>-0.202651</td>\n      <td>-0.190083</td>\n      <td>0.119905</td>\n      <td>-0.123321</td>\n      <td>0.182307</td>\n      <td>0.143203</td>\n      <td>0.209402</td>\n      <td>-0.173884</td>\n      <td>-0.024432</td>\n      <td>0.126823</td>\n      <td>-0.146663</td>\n      <td>0.087687</td>\n      <td>-0.082982</td>\n      <td>-0.111908</td>\n      <td>-0.087379</td>\n      <td>0.047548</td>\n      <td>-0.117474</td>\n      <td>-0.113212</td>\n      <td>-0.052746</td>\n      <td>-0.091055</td>\n      <td>0.112176</td>\n      <td>-0.046458</td>\n      <td>-0.076239</td>\n      <td>-0.197699</td>\n      <td>0.382177</td>\n      <td>-0.189432</td>\n      <td>0.078791</td>\n      <td>-0.093312</td>\n      <td>0.135729</td>\n      <td>-0.188616</td>\n      <td>-0.606710</td>\n      <td>0.534425</td>\n      <td>...</td>\n      <td>-0.517397</td>\n      <td>-0.360770</td>\n      <td>-0.435752</td>\n      <td>-0.613591</td>\n      <td>-0.402083</td>\n      <td>-0.619682</td>\n      <td>-0.452265</td>\n      <td>-0.497164</td>\n      <td>-0.413836</td>\n      <td>-0.277029</td>\n      <td>-0.547845</td>\n      <td>-0.358611</td>\n      <td>-0.442906</td>\n      <td>-0.475194</td>\n      <td>-0.010404</td>\n      <td>-0.467001</td>\n      <td>-0.276963</td>\n      <td>-0.455848</td>\n      <td>-0.412918</td>\n      <td>-0.456404</td>\n      <td>-0.472514</td>\n      <td>-0.505481</td>\n      <td>-0.492735</td>\n      <td>-0.446836</td>\n      <td>-0.463029</td>\n      <td>-0.409310</td>\n      <td>-0.333124</td>\n      <td>-0.295009</td>\n      <td>-0.328342</td>\n      <td>-0.401615</td>\n      <td>-0.469244</td>\n      <td>-0.461411</td>\n      <td>-0.513256</td>\n      <td>-0.500142</td>\n      <td>-0.507093</td>\n      <td>-0.353726</td>\n      <td>-0.463485</td>\n      <td>-0.378241</td>\n      <td>-0.470252</td>\n      <td>-0.301505</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>19.402807</td>\n      <td>1.393399</td>\n      <td>0.812363</td>\n      <td>1.035731</td>\n      <td>0.950012</td>\n      <td>1.032091</td>\n      <td>1.179388</td>\n      <td>0.882395</td>\n      <td>1.125494</td>\n      <td>1.749885</td>\n      <td>1.087180</td>\n      <td>1.291501</td>\n      <td>1.253604</td>\n      <td>1.234590</td>\n      <td>1.273068</td>\n      <td>1.247178</td>\n      <td>0.659839</td>\n      <td>1.418997</td>\n      <td>1.179688</td>\n      <td>0.743301</td>\n      <td>0.844796</td>\n      <td>1.219529</td>\n      <td>0.824401</td>\n      <td>0.924838</td>\n      <td>0.760159</td>\n      <td>1.203186</td>\n      <td>0.866977</td>\n      <td>1.103765</td>\n      <td>1.001687</td>\n      <td>1.027758</td>\n      <td>1.279399</td>\n      <td>1.302567</td>\n      <td>1.559174</td>\n      <td>0.933514</td>\n      <td>1.172270</td>\n      <td>1.174325</td>\n      <td>1.061719</td>\n      <td>1.397677</td>\n      <td>2.200277</td>\n      <td>2.003317</td>\n      <td>...</td>\n      <td>2.122318</td>\n      <td>1.710725</td>\n      <td>1.898871</td>\n      <td>2.307820</td>\n      <td>1.785055</td>\n      <td>2.225596</td>\n      <td>1.991021</td>\n      <td>2.063896</td>\n      <td>1.887001</td>\n      <td>1.459639</td>\n      <td>2.187835</td>\n      <td>1.730634</td>\n      <td>1.924716</td>\n      <td>2.021927</td>\n      <td>1.029820</td>\n      <td>2.004317</td>\n      <td>1.429340</td>\n      <td>1.924263</td>\n      <td>1.888788</td>\n      <td>1.832863</td>\n      <td>2.011396</td>\n      <td>2.091353</td>\n      <td>2.055624</td>\n      <td>1.987476</td>\n      <td>2.014045</td>\n      <td>1.883974</td>\n      <td>1.647241</td>\n      <td>1.634073</td>\n      <td>1.663170</td>\n      <td>1.832794</td>\n      <td>2.000488</td>\n      <td>2.042475</td>\n      <td>2.001714</td>\n      <td>2.107105</td>\n      <td>2.159589</td>\n      <td>1.629291</td>\n      <td>2.059725</td>\n      <td>1.703615</td>\n      <td>1.834828</td>\n      <td>1.407918</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>24.000000</td>\n      <td>-5.513000</td>\n      <td>-5.737000</td>\n      <td>-9.104000</td>\n      <td>-5.998000</td>\n      <td>-6.369000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-8.337000</td>\n      <td>-10.000000</td>\n      <td>-5.870000</td>\n      <td>-8.587000</td>\n      <td>-5.018000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-4.226000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-5.700000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-8.272000</td>\n      <td>-8.184000</td>\n      <td>-4.835000</td>\n      <td>-7.913000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-2.956000</td>\n      <td>-8.356000</td>\n      <td>-7.182000</td>\n      <td>-10.000000</td>\n      <td>-9.261000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>...</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-9.839000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-6.452000</td>\n      <td>-10.000000</td>\n      <td>-9.938000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n      <td>-10.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>24.000000</td>\n      <td>-0.473075</td>\n      <td>-0.562200</td>\n      <td>-0.437750</td>\n      <td>-0.429575</td>\n      <td>-0.470925</td>\n      <td>-0.602225</td>\n      <td>-0.493900</td>\n      <td>-0.525175</td>\n      <td>-0.511675</td>\n      <td>-0.360200</td>\n      <td>-0.511475</td>\n      <td>-0.489675</td>\n      <td>-0.447500</td>\n      <td>-0.481200</td>\n      <td>-0.607975</td>\n      <td>-0.404150</td>\n      <td>-0.391950</td>\n      <td>-0.513775</td>\n      <td>-0.272200</td>\n      <td>-0.488675</td>\n      <td>-0.524600</td>\n      <td>-0.538900</td>\n      <td>-0.440375</td>\n      <td>-0.508900</td>\n      <td>-0.533900</td>\n      <td>-0.497700</td>\n      <td>-0.512875</td>\n      <td>-0.467800</td>\n      <td>-0.378300</td>\n      <td>-0.505750</td>\n      <td>-0.457975</td>\n      <td>-0.328200</td>\n      <td>-0.600500</td>\n      <td>-0.478700</td>\n      <td>-0.570525</td>\n      <td>-0.481800</td>\n      <td>-0.541950</td>\n      <td>-0.604100</td>\n      <td>-0.470250</td>\n      <td>...</td>\n      <td>-0.588075</td>\n      <td>-0.564025</td>\n      <td>-0.561000</td>\n      <td>-0.583250</td>\n      <td>-0.566500</td>\n      <td>-0.603200</td>\n      <td>-0.541575</td>\n      <td>-0.560825</td>\n      <td>-0.555200</td>\n      <td>-0.534500</td>\n      <td>-0.569100</td>\n      <td>-0.558300</td>\n      <td>-0.573350</td>\n      <td>-0.594275</td>\n      <td>-0.389925</td>\n      <td>-0.551200</td>\n      <td>-0.544150</td>\n      <td>-0.575075</td>\n      <td>-0.568275</td>\n      <td>-0.582650</td>\n      <td>-0.558575</td>\n      <td>-0.562375</td>\n      <td>-0.572800</td>\n      <td>-0.561225</td>\n      <td>-0.560675</td>\n      <td>-0.560100</td>\n      <td>-0.533700</td>\n      <td>-0.504575</td>\n      <td>-0.544275</td>\n      <td>-0.569150</td>\n      <td>-0.566175</td>\n      <td>-0.565975</td>\n      <td>-0.589975</td>\n      <td>-0.568700</td>\n      <td>-0.563775</td>\n      <td>-0.567975</td>\n      <td>-0.552575</td>\n      <td>-0.561000</td>\n      <td>-0.592600</td>\n      <td>-0.562900</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>48.000000</td>\n      <td>-0.008850</td>\n      <td>-0.046600</td>\n      <td>0.075200</td>\n      <td>0.008050</td>\n      <td>-0.026900</td>\n      <td>-0.015650</td>\n      <td>-0.000650</td>\n      <td>-0.017900</td>\n      <td>0.010000</td>\n      <td>0.160450</td>\n      <td>0.038550</td>\n      <td>0.013800</td>\n      <td>0.060250</td>\n      <td>0.009800</td>\n      <td>-0.030100</td>\n      <td>0.000000</td>\n      <td>0.149400</td>\n      <td>-0.002200</td>\n      <td>0.000000</td>\n      <td>-0.027800</td>\n      <td>-0.002800</td>\n      <td>-0.069350</td>\n      <td>-0.011800</td>\n      <td>0.000000</td>\n      <td>0.018300</td>\n      <td>-0.011650</td>\n      <td>0.016100</td>\n      <td>0.037600</td>\n      <td>0.003750</td>\n      <td>0.021750</td>\n      <td>0.027000</td>\n      <td>0.019100</td>\n      <td>-0.054000</td>\n      <td>0.023350</td>\n      <td>0.003350</td>\n      <td>-0.000600</td>\n      <td>0.015350</td>\n      <td>-0.000700</td>\n      <td>0.005800</td>\n      <td>...</td>\n      <td>-0.017650</td>\n      <td>-0.041550</td>\n      <td>-0.002950</td>\n      <td>-0.012650</td>\n      <td>-0.005600</td>\n      <td>0.007650</td>\n      <td>0.004950</td>\n      <td>0.000000</td>\n      <td>-0.023800</td>\n      <td>-0.011450</td>\n      <td>-0.007100</td>\n      <td>-0.019500</td>\n      <td>-0.019500</td>\n      <td>-0.009300</td>\n      <td>0.081550</td>\n      <td>-0.006900</td>\n      <td>0.018400</td>\n      <td>-0.014650</td>\n      <td>-0.014350</td>\n      <td>0.005300</td>\n      <td>-0.005300</td>\n      <td>-0.004050</td>\n      <td>0.003300</td>\n      <td>-0.007900</td>\n      <td>-0.004600</td>\n      <td>-0.002400</td>\n      <td>0.007850</td>\n      <td>-0.005600</td>\n      <td>-0.020600</td>\n      <td>-0.030000</td>\n      <td>-0.009900</td>\n      <td>0.003250</td>\n      <td>-0.009100</td>\n      <td>-0.013750</td>\n      <td>-0.003300</td>\n      <td>-0.010250</td>\n      <td>-0.001250</td>\n      <td>-0.006800</td>\n      <td>0.014000</td>\n      <td>-0.019500</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>72.000000</td>\n      <td>0.525700</td>\n      <td>0.403075</td>\n      <td>0.663925</td>\n      <td>0.463400</td>\n      <td>0.465375</td>\n      <td>0.510425</td>\n      <td>0.528725</td>\n      <td>0.411900</td>\n      <td>0.549225</td>\n      <td>0.697775</td>\n      <td>0.525400</td>\n      <td>0.575275</td>\n      <td>0.604450</td>\n      <td>0.575825</td>\n      <td>0.457975</td>\n      <td>0.382475</td>\n      <td>0.829500</td>\n      <td>0.494775</td>\n      <td>0.327800</td>\n      <td>0.400600</td>\n      <td>0.492400</td>\n      <td>0.414875</td>\n      <td>0.433400</td>\n      <td>0.329250</td>\n      <td>0.527700</td>\n      <td>0.461650</td>\n      <td>0.508425</td>\n      <td>0.586450</td>\n      <td>0.431275</td>\n      <td>0.507600</td>\n      <td>0.458075</td>\n      <td>0.471075</td>\n      <td>0.391950</td>\n      <td>0.551300</td>\n      <td>0.503725</td>\n      <td>0.564875</td>\n      <td>0.517025</td>\n      <td>0.460500</td>\n      <td>0.642300</td>\n      <td>...</td>\n      <td>0.452675</td>\n      <td>0.427675</td>\n      <td>0.462175</td>\n      <td>0.447975</td>\n      <td>0.447150</td>\n      <td>0.441250</td>\n      <td>0.470600</td>\n      <td>0.458550</td>\n      <td>0.441000</td>\n      <td>0.460075</td>\n      <td>0.460950</td>\n      <td>0.449975</td>\n      <td>0.445200</td>\n      <td>0.473200</td>\n      <td>0.563575</td>\n      <td>0.456350</td>\n      <td>0.493400</td>\n      <td>0.448375</td>\n      <td>0.451975</td>\n      <td>0.463075</td>\n      <td>0.447675</td>\n      <td>0.462000</td>\n      <td>0.468900</td>\n      <td>0.452375</td>\n      <td>0.460475</td>\n      <td>0.461675</td>\n      <td>0.465950</td>\n      <td>0.463400</td>\n      <td>0.450075</td>\n      <td>0.430875</td>\n      <td>0.457750</td>\n      <td>0.461500</td>\n      <td>0.445675</td>\n      <td>0.452900</td>\n      <td>0.470900</td>\n      <td>0.444750</td>\n      <td>0.465225</td>\n      <td>0.446400</td>\n      <td>0.461275</td>\n      <td>0.438650</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>72.000000</td>\n      <td>10.000000</td>\n      <td>5.039000</td>\n      <td>8.257000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>7.282000</td>\n      <td>7.333000</td>\n      <td>5.473000</td>\n      <td>8.887000</td>\n      <td>6.433000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>4.134000</td>\n      <td>6.418000</td>\n      <td>4.750000</td>\n      <td>8.872000</td>\n      <td>4.081000</td>\n      <td>9.842000</td>\n      <td>5.248000</td>\n      <td>5.942000</td>\n      <td>5.201000</td>\n      <td>10.000000</td>\n      <td>8.494000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>9.416000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>6.796000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>5.834000</td>\n      <td>5.602000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>3.888000</td>\n      <td>3.596000</td>\n      <td>4.857000</td>\n      <td>3.549000</td>\n      <td>3.382000</td>\n      <td>3.328000</td>\n      <td>4.157000</td>\n      <td>3.736000</td>\n      <td>3.582000</td>\n      <td>3.119000</td>\n      <td>3.323000</td>\n      <td>5.014000</td>\n      <td>2.898000</td>\n      <td>4.185000</td>\n      <td>3.170000</td>\n      <td>3.276000</td>\n      <td>4.992000</td>\n      <td>3.770000</td>\n      <td>2.851000</td>\n      <td>3.211000</td>\n      <td>4.534000</td>\n      <td>3.890000</td>\n      <td>3.994000</td>\n      <td>4.321000</td>\n      <td>4.020000</td>\n      <td>3.738000</td>\n      <td>3.252000</td>\n      <td>5.406000</td>\n      <td>3.110000</td>\n      <td>3.320000</td>\n      <td>4.069000</td>\n      <td>3.960000</td>\n      <td>3.927000</td>\n      <td>3.596000</td>\n      <td>3.747000</td>\n      <td>2.814000</td>\n      <td>3.505000</td>\n      <td>2.924000</td>\n      <td>3.111000</td>\n      <td>3.805000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 873 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 228
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "!pip install scikit-multilearn\n",
    "\n",
    "BASE_PATH='../../data/lish-moa'\n",
    "TRAIN_X_FILE='train_features.csv'\n",
    "TEST_X_FILE='test_features.csv'\n",
    "\n",
    "TRAIN_y_FILE='train_targets_scored.csv'\n",
    "\n",
    "df_target= pd.read_csv(os.path.join(BASE_PATH, TRAIN_y_FILE), header = 0)\n",
    "df_features= pd.read_csv(os.path.join(BASE_PATH, TRAIN_X_FILE), header = 0)\n",
    "df_test_features=pd.read_csv(os.path.join(BASE_PATH, TEST_X_FILE), header = 0)\n",
    "\n",
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       5-alpha_reductase_inhibitor  ...  wnt_inhibitor\ncount                 23814.000000  ...   23814.000000\nmean                      0.000714  ...       0.001260\nstd                       0.026709  ...       0.035472\nmin                       0.000000  ...       0.000000\n25%                       0.000000  ...       0.000000\n50%                       0.000000  ...       0.000000\n75%                       0.000000  ...       0.000000\nmax                       1.000000  ...       1.000000\n\n[8 rows x 206 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>adrenergic_receptor_antagonist</th>\n      <th>akt_inhibitor</th>\n      <th>aldehyde_dehydrogenase_inhibitor</th>\n      <th>alk_inhibitor</th>\n      <th>ampk_activator</th>\n      <th>analgesic</th>\n      <th>androgen_receptor_agonist</th>\n      <th>androgen_receptor_antagonist</th>\n      <th>anesthetic_-_local</th>\n      <th>angiogenesis_inhibitor</th>\n      <th>angiotensin_receptor_antagonist</th>\n      <th>anti-inflammatory</th>\n      <th>antiarrhythmic</th>\n      <th>antibiotic</th>\n      <th>anticonvulsant</th>\n      <th>antifungal</th>\n      <th>antihistamine</th>\n      <th>antimalarial</th>\n      <th>antioxidant</th>\n      <th>antiprotozoal</th>\n      <th>antiviral</th>\n      <th>apoptosis_stimulant</th>\n      <th>aromatase_inhibitor</th>\n      <th>atm_kinase_inhibitor</th>\n      <th>atp-sensitive_potassium_channel_antagonist</th>\n      <th>atp_synthase_inhibitor</th>\n      <th>atpase_inhibitor</th>\n      <th>atr_kinase_inhibitor</th>\n      <th>aurora_kinase_inhibitor</th>\n      <th>autotaxin_inhibitor</th>\n      <th>...</th>\n      <th>protein_synthesis_inhibitor</th>\n      <th>protein_tyrosine_kinase_inhibitor</th>\n      <th>radiopaque_medium</th>\n      <th>raf_inhibitor</th>\n      <th>ras_gtpase_inhibitor</th>\n      <th>retinoid_receptor_agonist</th>\n      <th>retinoid_receptor_antagonist</th>\n      <th>rho_associated_kinase_inhibitor</th>\n      <th>ribonucleoside_reductase_inhibitor</th>\n      <th>rna_polymerase_inhibitor</th>\n      <th>serotonin_receptor_agonist</th>\n      <th>serotonin_receptor_antagonist</th>\n      <th>serotonin_reuptake_inhibitor</th>\n      <th>sigma_receptor_agonist</th>\n      <th>sigma_receptor_antagonist</th>\n      <th>smoothened_receptor_antagonist</th>\n      <th>sodium_channel_inhibitor</th>\n      <th>sphingosine_receptor_agonist</th>\n      <th>src_inhibitor</th>\n      <th>steroid</th>\n      <th>syk_inhibitor</th>\n      <th>tachykinin_antagonist</th>\n      <th>tgf-beta_receptor_inhibitor</th>\n      <th>thrombin_inhibitor</th>\n      <th>thymidylate_synthase_inhibitor</th>\n      <th>tlr_agonist</th>\n      <th>tlr_antagonist</th>\n      <th>tnf_inhibitor</th>\n      <th>topoisomerase_inhibitor</th>\n      <th>transient_receptor_potential_channel_antagonist</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>...</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.00000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n      <td>23814.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000714</td>\n      <td>0.000756</td>\n      <td>0.001008</td>\n      <td>0.007979</td>\n      <td>0.012640</td>\n      <td>0.003065</td>\n      <td>0.002268</td>\n      <td>0.004031</td>\n      <td>0.000504</td>\n      <td>0.011338</td>\n      <td>0.015117</td>\n      <td>0.002771</td>\n      <td>0.000294</td>\n      <td>0.001764</td>\n      <td>0.000504</td>\n      <td>0.000504</td>\n      <td>0.002016</td>\n      <td>0.003737</td>\n      <td>0.003359</td>\n      <td>0.001512</td>\n      <td>0.001554</td>\n      <td>0.003065</td>\n      <td>0.000252</td>\n      <td>0.001806</td>\n      <td>0.000504</td>\n      <td>0.000546</td>\n      <td>0.000504</td>\n      <td>0.000756</td>\n      <td>0.003065</td>\n      <td>0.001512</td>\n      <td>0.000966</td>\n      <td>0.002058</td>\n      <td>0.001974</td>\n      <td>0.000252</td>\n      <td>0.000042</td>\n      <td>0.000504</td>\n      <td>0.004073</td>\n      <td>0.000798</td>\n      <td>0.004031</td>\n      <td>0.000252</td>\n      <td>...</td>\n      <td>0.004325</td>\n      <td>0.000798</td>\n      <td>0.002352</td>\n      <td>0.009364</td>\n      <td>0.000504</td>\n      <td>0.002813</td>\n      <td>0.000252</td>\n      <td>0.00147</td>\n      <td>0.001554</td>\n      <td>0.001050</td>\n      <td>0.009910</td>\n      <td>0.016965</td>\n      <td>0.001848</td>\n      <td>0.001512</td>\n      <td>0.001512</td>\n      <td>0.001050</td>\n      <td>0.011212</td>\n      <td>0.001050</td>\n      <td>0.002981</td>\n      <td>0.000252</td>\n      <td>0.000798</td>\n      <td>0.002520</td>\n      <td>0.001260</td>\n      <td>0.000798</td>\n      <td>0.001554</td>\n      <td>0.001260</td>\n      <td>0.000294</td>\n      <td>0.001512</td>\n      <td>0.005333</td>\n      <td>0.000756</td>\n      <td>0.000252</td>\n      <td>0.001050</td>\n      <td>0.002016</td>\n      <td>0.013270</td>\n      <td>0.003065</td>\n      <td>0.000252</td>\n      <td>0.007139</td>\n      <td>0.001092</td>\n      <td>0.001638</td>\n      <td>0.001260</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.026709</td>\n      <td>0.027483</td>\n      <td>0.031731</td>\n      <td>0.088967</td>\n      <td>0.111716</td>\n      <td>0.055283</td>\n      <td>0.047566</td>\n      <td>0.063365</td>\n      <td>0.022443</td>\n      <td>0.105876</td>\n      <td>0.122022</td>\n      <td>0.052573</td>\n      <td>0.017143</td>\n      <td>0.041960</td>\n      <td>0.022443</td>\n      <td>0.022443</td>\n      <td>0.044851</td>\n      <td>0.061020</td>\n      <td>0.057864</td>\n      <td>0.038852</td>\n      <td>0.039387</td>\n      <td>0.055283</td>\n      <td>0.015871</td>\n      <td>0.042456</td>\n      <td>0.022443</td>\n      <td>0.023359</td>\n      <td>0.022443</td>\n      <td>0.027483</td>\n      <td>0.055283</td>\n      <td>0.038852</td>\n      <td>0.031063</td>\n      <td>0.045315</td>\n      <td>0.044383</td>\n      <td>0.015871</td>\n      <td>0.006480</td>\n      <td>0.022443</td>\n      <td>0.063693</td>\n      <td>0.028236</td>\n      <td>0.063365</td>\n      <td>0.015871</td>\n      <td>...</td>\n      <td>0.065625</td>\n      <td>0.028236</td>\n      <td>0.048437</td>\n      <td>0.096317</td>\n      <td>0.022443</td>\n      <td>0.052969</td>\n      <td>0.015871</td>\n      <td>0.03831</td>\n      <td>0.039387</td>\n      <td>0.032384</td>\n      <td>0.099057</td>\n      <td>0.129142</td>\n      <td>0.042946</td>\n      <td>0.038852</td>\n      <td>0.038852</td>\n      <td>0.032384</td>\n      <td>0.105293</td>\n      <td>0.032384</td>\n      <td>0.054522</td>\n      <td>0.015871</td>\n      <td>0.028236</td>\n      <td>0.050133</td>\n      <td>0.035472</td>\n      <td>0.028236</td>\n      <td>0.039387</td>\n      <td>0.035472</td>\n      <td>0.017143</td>\n      <td>0.038852</td>\n      <td>0.072834</td>\n      <td>0.027483</td>\n      <td>0.015871</td>\n      <td>0.032384</td>\n      <td>0.044851</td>\n      <td>0.114429</td>\n      <td>0.055283</td>\n      <td>0.015871</td>\n      <td>0.084190</td>\n      <td>0.033025</td>\n      <td>0.040436</td>\n      <td>0.035472</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 206 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "\n",
    "df_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             sig_id  ...  wnt_inhibitor\n23809  id_fffb1ceed  ...              0\n23810  id_fffb70c0c  ...              0\n23811  id_fffc1c3f4  ...              0\n23812  id_fffcb9e7c  ...              0\n23813  id_ffffdd77b  ...              0\n\n[5 rows x 207 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>adrenergic_receptor_antagonist</th>\n      <th>akt_inhibitor</th>\n      <th>aldehyde_dehydrogenase_inhibitor</th>\n      <th>alk_inhibitor</th>\n      <th>ampk_activator</th>\n      <th>analgesic</th>\n      <th>androgen_receptor_agonist</th>\n      <th>androgen_receptor_antagonist</th>\n      <th>anesthetic_-_local</th>\n      <th>angiogenesis_inhibitor</th>\n      <th>angiotensin_receptor_antagonist</th>\n      <th>anti-inflammatory</th>\n      <th>antiarrhythmic</th>\n      <th>antibiotic</th>\n      <th>anticonvulsant</th>\n      <th>antifungal</th>\n      <th>antihistamine</th>\n      <th>antimalarial</th>\n      <th>antioxidant</th>\n      <th>antiprotozoal</th>\n      <th>antiviral</th>\n      <th>apoptosis_stimulant</th>\n      <th>aromatase_inhibitor</th>\n      <th>atm_kinase_inhibitor</th>\n      <th>atp-sensitive_potassium_channel_antagonist</th>\n      <th>atp_synthase_inhibitor</th>\n      <th>atpase_inhibitor</th>\n      <th>atr_kinase_inhibitor</th>\n      <th>aurora_kinase_inhibitor</th>\n      <th>...</th>\n      <th>protein_synthesis_inhibitor</th>\n      <th>protein_tyrosine_kinase_inhibitor</th>\n      <th>radiopaque_medium</th>\n      <th>raf_inhibitor</th>\n      <th>ras_gtpase_inhibitor</th>\n      <th>retinoid_receptor_agonist</th>\n      <th>retinoid_receptor_antagonist</th>\n      <th>rho_associated_kinase_inhibitor</th>\n      <th>ribonucleoside_reductase_inhibitor</th>\n      <th>rna_polymerase_inhibitor</th>\n      <th>serotonin_receptor_agonist</th>\n      <th>serotonin_receptor_antagonist</th>\n      <th>serotonin_reuptake_inhibitor</th>\n      <th>sigma_receptor_agonist</th>\n      <th>sigma_receptor_antagonist</th>\n      <th>smoothened_receptor_antagonist</th>\n      <th>sodium_channel_inhibitor</th>\n      <th>sphingosine_receptor_agonist</th>\n      <th>src_inhibitor</th>\n      <th>steroid</th>\n      <th>syk_inhibitor</th>\n      <th>tachykinin_antagonist</th>\n      <th>tgf-beta_receptor_inhibitor</th>\n      <th>thrombin_inhibitor</th>\n      <th>thymidylate_synthase_inhibitor</th>\n      <th>tlr_agonist</th>\n      <th>tlr_antagonist</th>\n      <th>tnf_inhibitor</th>\n      <th>topoisomerase_inhibitor</th>\n      <th>transient_receptor_potential_channel_antagonist</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23809</th>\n      <td>id_fffb1ceed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23810</th>\n      <td>id_fffb70c0c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23811</th>\n      <td>id_fffc1c3f4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23812</th>\n      <td>id_fffcb9e7c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23813</th>\n      <td>id_ffffdd77b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 207 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 230
    }
   ],
   "source": [
    "df_target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         sig_id cp_type  cp_time cp_dose  ...    c-96    c-97    c-98    c-99\n0  id_000644bb2  trt_cp       24      D1  ... -0.3981  0.2139  0.3801  0.4176\n1  id_000779bfc  trt_cp       72      D1  ...  0.1522  0.1241  0.6077  0.7371\n\n[2 rows x 876 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>cp_type</th>\n      <th>cp_time</th>\n      <th>cp_dose</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>g-6</th>\n      <th>g-7</th>\n      <th>g-8</th>\n      <th>g-9</th>\n      <th>g-10</th>\n      <th>g-11</th>\n      <th>g-12</th>\n      <th>g-13</th>\n      <th>g-14</th>\n      <th>g-15</th>\n      <th>g-16</th>\n      <th>g-17</th>\n      <th>g-18</th>\n      <th>g-19</th>\n      <th>g-20</th>\n      <th>g-21</th>\n      <th>g-22</th>\n      <th>g-23</th>\n      <th>g-24</th>\n      <th>g-25</th>\n      <th>g-26</th>\n      <th>g-27</th>\n      <th>g-28</th>\n      <th>g-29</th>\n      <th>g-30</th>\n      <th>g-31</th>\n      <th>g-32</th>\n      <th>g-33</th>\n      <th>g-34</th>\n      <th>g-35</th>\n      <th>...</th>\n      <th>c-60</th>\n      <th>c-61</th>\n      <th>c-62</th>\n      <th>c-63</th>\n      <th>c-64</th>\n      <th>c-65</th>\n      <th>c-66</th>\n      <th>c-67</th>\n      <th>c-68</th>\n      <th>c-69</th>\n      <th>c-70</th>\n      <th>c-71</th>\n      <th>c-72</th>\n      <th>c-73</th>\n      <th>c-74</th>\n      <th>c-75</th>\n      <th>c-76</th>\n      <th>c-77</th>\n      <th>c-78</th>\n      <th>c-79</th>\n      <th>c-80</th>\n      <th>c-81</th>\n      <th>c-82</th>\n      <th>c-83</th>\n      <th>c-84</th>\n      <th>c-85</th>\n      <th>c-86</th>\n      <th>c-87</th>\n      <th>c-88</th>\n      <th>c-89</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_000644bb2</td>\n      <td>trt_cp</td>\n      <td>24</td>\n      <td>D1</td>\n      <td>1.0620</td>\n      <td>0.5577</td>\n      <td>-0.2479</td>\n      <td>-0.6208</td>\n      <td>-0.1944</td>\n      <td>-1.0120</td>\n      <td>-1.0220</td>\n      <td>-0.0326</td>\n      <td>0.5548</td>\n      <td>-0.0921</td>\n      <td>1.183</td>\n      <td>0.1530</td>\n      <td>0.5574</td>\n      <td>-0.4015</td>\n      <td>0.1789</td>\n      <td>-0.6528</td>\n      <td>-0.7969</td>\n      <td>0.6342</td>\n      <td>0.1778</td>\n      <td>-0.3694</td>\n      <td>-0.5688</td>\n      <td>-1.1360</td>\n      <td>-1.1880</td>\n      <td>0.6940</td>\n      <td>0.4393</td>\n      <td>0.2664</td>\n      <td>0.1907</td>\n      <td>0.1628</td>\n      <td>-0.2853</td>\n      <td>0.5819</td>\n      <td>0.2934</td>\n      <td>-0.5584</td>\n      <td>-0.0916</td>\n      <td>-0.3010</td>\n      <td>-0.1537</td>\n      <td>0.2198</td>\n      <td>...</td>\n      <td>0.4805</td>\n      <td>0.4965</td>\n      <td>0.3680</td>\n      <td>0.8427</td>\n      <td>0.1042</td>\n      <td>0.1403</td>\n      <td>0.1758</td>\n      <td>1.2570</td>\n      <td>-0.5979</td>\n      <td>1.2250</td>\n      <td>-0.0553</td>\n      <td>0.7351</td>\n      <td>0.5810</td>\n      <td>0.9590</td>\n      <td>0.2427</td>\n      <td>0.0495</td>\n      <td>0.4141</td>\n      <td>0.8432</td>\n      <td>0.6162</td>\n      <td>-0.7318</td>\n      <td>1.2120</td>\n      <td>0.6362</td>\n      <td>-0.4427</td>\n      <td>0.1288</td>\n      <td>1.4840</td>\n      <td>0.1799</td>\n      <td>0.5367</td>\n      <td>-0.1111</td>\n      <td>-1.0120</td>\n      <td>0.6685</td>\n      <td>0.2862</td>\n      <td>0.2584</td>\n      <td>0.8076</td>\n      <td>0.5523</td>\n      <td>-0.1912</td>\n      <td>0.6584</td>\n      <td>-0.3981</td>\n      <td>0.2139</td>\n      <td>0.3801</td>\n      <td>0.4176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_000779bfc</td>\n      <td>trt_cp</td>\n      <td>72</td>\n      <td>D1</td>\n      <td>0.0743</td>\n      <td>0.4087</td>\n      <td>0.2991</td>\n      <td>0.0604</td>\n      <td>1.0190</td>\n      <td>0.5207</td>\n      <td>0.2341</td>\n      <td>0.3372</td>\n      <td>-0.4047</td>\n      <td>0.8507</td>\n      <td>-1.152</td>\n      <td>-0.4201</td>\n      <td>-0.0958</td>\n      <td>0.4590</td>\n      <td>0.0803</td>\n      <td>0.2250</td>\n      <td>0.5293</td>\n      <td>0.2839</td>\n      <td>-0.3494</td>\n      <td>0.2883</td>\n      <td>0.9449</td>\n      <td>-0.1646</td>\n      <td>-0.2657</td>\n      <td>-0.3372</td>\n      <td>0.3135</td>\n      <td>-0.4316</td>\n      <td>0.4773</td>\n      <td>0.2075</td>\n      <td>-0.4216</td>\n      <td>-0.1161</td>\n      <td>-0.0499</td>\n      <td>-0.2627</td>\n      <td>0.9959</td>\n      <td>-0.2483</td>\n      <td>0.2655</td>\n      <td>-0.2102</td>\n      <td>...</td>\n      <td>0.4083</td>\n      <td>0.0319</td>\n      <td>0.3905</td>\n      <td>0.7099</td>\n      <td>0.2912</td>\n      <td>0.4151</td>\n      <td>-0.2840</td>\n      <td>-0.3104</td>\n      <td>-0.6373</td>\n      <td>0.2887</td>\n      <td>-0.0765</td>\n      <td>0.2539</td>\n      <td>0.4443</td>\n      <td>0.5932</td>\n      <td>0.2031</td>\n      <td>0.7639</td>\n      <td>0.5499</td>\n      <td>-0.3322</td>\n      <td>-0.0977</td>\n      <td>0.4329</td>\n      <td>-0.2782</td>\n      <td>0.7827</td>\n      <td>0.5934</td>\n      <td>0.3402</td>\n      <td>0.1499</td>\n      <td>0.4420</td>\n      <td>0.9366</td>\n      <td>0.8193</td>\n      <td>-0.4236</td>\n      <td>0.3192</td>\n      <td>-0.4265</td>\n      <td>0.7543</td>\n      <td>0.4708</td>\n      <td>0.0230</td>\n      <td>0.2957</td>\n      <td>0.4899</td>\n      <td>0.1522</td>\n      <td>0.1241</td>\n      <td>0.6077</td>\n      <td>0.7371</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 876 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "source": [
    "df_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       5-alpha_reductase_inhibitor  ...  wnt_inhibitor\n0                                0  ...              0\n1                                0  ...              0\n2                                0  ...              0\n3                                0  ...              0\n4                                0  ...              0\n...                            ...  ...            ...\n23809                            0  ...              0\n23810                            0  ...              0\n23811                            0  ...              0\n23812                            0  ...              0\n23813                            0  ...              0\n\n[23814 rows x 206 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>adrenergic_receptor_antagonist</th>\n      <th>akt_inhibitor</th>\n      <th>aldehyde_dehydrogenase_inhibitor</th>\n      <th>alk_inhibitor</th>\n      <th>ampk_activator</th>\n      <th>analgesic</th>\n      <th>androgen_receptor_agonist</th>\n      <th>androgen_receptor_antagonist</th>\n      <th>anesthetic_-_local</th>\n      <th>angiogenesis_inhibitor</th>\n      <th>angiotensin_receptor_antagonist</th>\n      <th>anti-inflammatory</th>\n      <th>antiarrhythmic</th>\n      <th>antibiotic</th>\n      <th>anticonvulsant</th>\n      <th>antifungal</th>\n      <th>antihistamine</th>\n      <th>antimalarial</th>\n      <th>antioxidant</th>\n      <th>antiprotozoal</th>\n      <th>antiviral</th>\n      <th>apoptosis_stimulant</th>\n      <th>aromatase_inhibitor</th>\n      <th>atm_kinase_inhibitor</th>\n      <th>atp-sensitive_potassium_channel_antagonist</th>\n      <th>atp_synthase_inhibitor</th>\n      <th>atpase_inhibitor</th>\n      <th>atr_kinase_inhibitor</th>\n      <th>aurora_kinase_inhibitor</th>\n      <th>autotaxin_inhibitor</th>\n      <th>...</th>\n      <th>protein_synthesis_inhibitor</th>\n      <th>protein_tyrosine_kinase_inhibitor</th>\n      <th>radiopaque_medium</th>\n      <th>raf_inhibitor</th>\n      <th>ras_gtpase_inhibitor</th>\n      <th>retinoid_receptor_agonist</th>\n      <th>retinoid_receptor_antagonist</th>\n      <th>rho_associated_kinase_inhibitor</th>\n      <th>ribonucleoside_reductase_inhibitor</th>\n      <th>rna_polymerase_inhibitor</th>\n      <th>serotonin_receptor_agonist</th>\n      <th>serotonin_receptor_antagonist</th>\n      <th>serotonin_reuptake_inhibitor</th>\n      <th>sigma_receptor_agonist</th>\n      <th>sigma_receptor_antagonist</th>\n      <th>smoothened_receptor_antagonist</th>\n      <th>sodium_channel_inhibitor</th>\n      <th>sphingosine_receptor_agonist</th>\n      <th>src_inhibitor</th>\n      <th>steroid</th>\n      <th>syk_inhibitor</th>\n      <th>tachykinin_antagonist</th>\n      <th>tgf-beta_receptor_inhibitor</th>\n      <th>thrombin_inhibitor</th>\n      <th>thymidylate_synthase_inhibitor</th>\n      <th>tlr_agonist</th>\n      <th>tlr_antagonist</th>\n      <th>tnf_inhibitor</th>\n      <th>topoisomerase_inhibitor</th>\n      <th>transient_receptor_potential_channel_antagonist</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23809</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23810</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23811</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23812</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23813</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23814 rows × 206 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "source": [
    "#df_target[(df_target != '0') & (df_target == '0')]\n",
    "#df_target[(df_target == 1)]\n",
    "df_target.iloc[:,1:].apply(pd.to_numeric)\n",
    "#df_target[df_target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'_is_copy': None,\n '_data': SingleBlockManager\n Items: Index(['gsk_inhibitor'], dtype='object')\n ObjectBlock: 1 dtype: object,\n '_item_cache': {},\n '_attrs': {},\n '_name': 0,\n '_subtyp': 'series',\n '_index': Index(['gsk_inhibitor'], dtype='object')}"
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "first_row = df_target.iloc[0, 1:]\n",
    "answer=np.where(first_row==1)\n",
    "vars(first_row[answer[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_feature, test_feature, train_target, test_target=train_test_split(df_features, df_target, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accurancy of training model is 0.33516237402015675\nAcuracy of model prediction is 0.13150822976150486\n"
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(train_feature.iloc[:,4:], train_target.iloc[:,4:])\n",
    "print('Accurancy of training model is {0}'.format(classifier.score(train_feature.iloc[:,4:], train_target.iloc[:,4:])))\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(test_feature.iloc[:,4:])\n",
    "\n",
    "print('Acuracy of model prediction is {0}'.format(accuracy_score(test_target.iloc[:,4:],predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test_tfidf)))\n",
    "    print(\"Hamming score: {}\".format(hamming_score(y_pred, y_test_tfidf)))\n",
    "    print(\"---\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-9243fe118235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnb_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    242\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    243\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=6, tol=None)\n",
    "lr = LogisticRegression()\n",
    "#mn = MultinomialNB()\n",
    "\n",
    "for classifier in [nb_clf, sgd, lr]:\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(df_features.iloc[:,4:], df_target.iloc[:,4:])\n",
    "    y_pred = clf.predict(df_test_features.iloc[:,4:])\n",
    "    print_score(y_pred, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=3)"
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(df_features.iloc[:,4:], df_target.iloc[:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predicted=clf.predict(df_test_features.iloc[:,4:])\n",
    "model_predicted = (model_predicted > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n"
    }
   ],
   "source": [
    "print(model_predicted)\n",
    "#accuracy_score(df_test_features.iloc[:,4:], model_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}